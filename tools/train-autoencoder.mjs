#!/usr/bin/env node
// Train a sparse autoencoder for minion feature compression.
// Reads data/datasets/minion-encodings.json (generated by tools/encode-minions.mjs)
// and writes weights to data/models/autoencoder.json.

import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const DATASET_PATH = path.join(__dirname, '..', 'data', 'datasets', 'minion-encodings.json');
const MODEL_PATH = path.join(__dirname, '..', 'data', 'models', 'autoencoder.json');

const DEFAULT_EPOCHS = 220;
const DEFAULT_BATCH = 64;
const DEFAULT_LR = 0.05;
const LATENT_SIZE = 20;
const HIDDEN_SIZE = 64;
const SPARSITY_RHO = 0.01;
const SPARSITY_BETA = 10.0;
const EPSILON = 1e-6;

function gaussian(mu = 0, sigma = 1) {
  let u = 0, v = 0;
  while (u === 0) u = Math.random();
  while (v === 0) v = Math.random();
  return mu + sigma * Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);
}

function zeros(len) {
  return new Array(len).fill(0);
}

function createMatrix(rows, cols, scale = 1) {
  const m = new Array(rows);
  for (let i = 0; i < rows; i++) {
    m[i] = new Array(cols);
    for (let j = 0; j < cols; j++) {
      m[i][j] = gaussian(0, scale);
    }
  }
  return m;
}

function matVecMul(mat, vec) {
  const out = new Array(mat.length);
  for (let i = 0; i < mat.length; i++) {
    const row = mat[i];
    let sum = 0;
    const n = Math.min(row.length, vec.length);
    for (let j = 0; j < n; j++) sum += row[j] * vec[j];
    out[i] = sum;
  }
  return out;
}

function relu(vec) {
  return vec.map((v) => (v > 0 ? v : 0));
}

function reluGrad(vec) {
  return vec.map((v) => (v > 0 ? 1 : 0));
}

function sigmoid(vec) {
  return vec.map((v) => 1 / (1 + Math.exp(-v)));
}

function sigmoidGrad(sig) {
  return sig.map((v) => v * (1 - v));
}

function vecAdd(a, b) {
  const out = new Array(a.length);
  for (let i = 0; i < a.length; i++) out[i] = (a[i] || 0) + (b[i] || 0);
  return out;
}

function vecSub(a, b) {
  const out = new Array(a.length);
  for (let i = 0; i < a.length; i++) out[i] = (a[i] || 0) - (b[i] || 0);
  return out;
}

function scalarDiv(vec, value) {
  if (!(value > 0)) return vec.slice();
  return vec.map((v) => v / value);
}

function shuffleInPlace(arr) {
  for (let i = arr.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [arr[i], arr[j]] = [arr[j], arr[i]];
  }
}

class SparseAutoencoder {
  constructor(inputSize, {
    latentSize = LATENT_SIZE,
    hiddenSize = HIDDEN_SIZE,
    learningRate = DEFAULT_LR,
    rho = SPARSITY_RHO,
    beta = SPARSITY_BETA,
  } = {}) {
    this.inputSize = inputSize;
    this.latentSize = latentSize;
    this.hiddenSize = Math.max(hiddenSize, latentSize);
    this.learningRate = learningRate;
    this.rho = rho;
    this.beta = beta;

    const scale1 = Math.sqrt(2 / Math.max(1, inputSize));
    const scale2 = Math.sqrt(2 / Math.max(1, this.hiddenSize));
    const scale3 = Math.sqrt(2 / Math.max(1, this.latentSize));

    this.W1 = createMatrix(this.hiddenSize, inputSize, scale1);
    this.b1 = zeros(this.hiddenSize);
    this.W2 = createMatrix(this.latentSize, this.hiddenSize, scale2);
    this.b2 = zeros(this.latentSize);
    this.W3 = createMatrix(this.hiddenSize, this.latentSize, scale3);
    this.b3 = zeros(this.hiddenSize);
    this.W4 = createMatrix(inputSize, this.hiddenSize, scale1);
    this.b4 = zeros(inputSize);
  }

  forward(x) {
    const z1 = vecAdd(matVecMul(this.W1, x), this.b1);
    const h1 = relu(z1);
    const z2 = vecAdd(matVecMul(this.W2, h1), this.b2);
    const latent = sigmoid(z2);
    const z3 = vecAdd(matVecMul(this.W3, latent), this.b3);
    const h3 = relu(z3);
    const z4 = vecAdd(matVecMul(this.W4, h3), this.b4);
    const output = z4; // linear reconstruction
    return { z1, h1, z2, latent, z3, h3, z4, output };
  }

  train(samples, { epochs = DEFAULT_EPOCHS, batchSize = DEFAULT_BATCH } = {}) {
    const dataset = samples.slice();
    const total = dataset.length;
    if (!total) throw new Error('SparseAutoencoder.train: empty dataset');

    let runningLoss = 0;
    for (let epoch = 0; epoch < epochs; epoch++) {
      shuffleInPlace(dataset);
      let epochLoss = 0;
      for (let start = 0; start < total; start += batchSize) {
        const batch = dataset.slice(start, start + batchSize);
        const batchSizeActual = batch.length;
        if (!batchSizeActual) continue;

        const caches = [];
        let latentSums = zeros(this.latentSize);
        for (const sample of batch) {
          const cache = this.forward(sample);
          cache.input = sample;
          caches.push(cache);
          latentSums = latentSums.map((v, idx) => v + (cache.latent[idx] || 0));
          const diff = vecSub(cache.output, sample);
          epochLoss += diff.reduce((sum, val) => sum + 0.5 * val * val, 0);
        }
        const latentMeans = latentSums.map((sum) => sum / batchSizeActual);
        const sparsityTerms = latentMeans.map((mean) => {
          const clamped = Math.min(1 - EPSILON, Math.max(EPSILON, mean));
          return this.beta * ((-this.rho / clamped) + ((1 - this.rho) / (1 - clamped)));
        });

        const gradW1 = createMatrix(this.hiddenSize, this.inputSize, 0);
        const gradB1 = zeros(this.hiddenSize);
        const gradW2 = createMatrix(this.latentSize, this.hiddenSize, 0);
        const gradB2 = zeros(this.latentSize);
        const gradW3 = createMatrix(this.hiddenSize, this.latentSize, 0);
        const gradB3 = zeros(this.hiddenSize);
        const gradW4 = createMatrix(this.inputSize, this.hiddenSize, 0);
        const gradB4 = zeros(this.inputSize);

        for (const cache of caches) {
          const { input, h1, latent, h3, z1, z2, z3, output } = cache;
          const delta4 = vecSub(output, input);

          for (let i = 0; i < gradW4.length; i++) {
            const row = gradW4[i];
            const d = delta4[i] || 0;
            gradB4[i] += d;
            for (let j = 0; j < row.length; j++) {
              row[j] += d * (h3[j] || 0);
            }
          }

          const reluGrad3 = reluGrad(z3);
          const delta3 = new Array(this.hiddenSize);
          for (let i = 0; i < this.hiddenSize; i++) {
            let sum = 0;
            for (let j = 0; j < this.inputSize; j++) {
              sum += (this.W4[j][i] || 0) * (delta4[j] || 0);
            }
            delta3[i] = sum * reluGrad3[i];
            gradB3[i] += delta3[i];
          }

          for (let i = 0; i < this.hiddenSize; i++) {
            const row = gradW3[i];
            const d = delta3[i] || 0;
            for (let j = 0; j < this.latentSize; j++) {
              row[j] += d * (latent[j] || 0);
            }
          }

          const sigmoidGrad2 = sigmoidGrad(latent);
          const delta2 = new Array(this.latentSize);
          for (let i = 0; i < this.latentSize; i++) {
            let sum = sparsityTerms[i] || 0;
            for (let j = 0; j < this.hiddenSize; j++) {
              sum += (this.W3[j][i] || 0) * (delta3[j] || 0);
            }
            delta2[i] = sum * sigmoidGrad2[i];
            gradB2[i] += delta2[i];
          }

          for (let i = 0; i < this.latentSize; i++) {
            const row = gradW2[i];
            const d = delta2[i] || 0;
            for (let j = 0; j < this.hiddenSize; j++) {
              row[j] += d * (h1[j] || 0);
            }
          }

          const reluGrad1 = reluGrad(z1);
          const delta1 = new Array(this.hiddenSize);
          for (let i = 0; i < this.hiddenSize; i++) {
            let sum = 0;
            for (let j = 0; j < this.latentSize; j++) {
              sum += (this.W2[j][i] || 0) * (delta2[j] || 0);
            }
            delta1[i] = sum * reluGrad1[i];
            gradB1[i] += delta1[i];
          }

          for (let i = 0; i < this.hiddenSize; i++) {
            const row = gradW1[i];
            const d = delta1[i] || 0;
            for (let j = 0; j < this.inputSize; j++) {
              row[j] += d * (input[j] || 0);
            }
          }
        }

        const scale = this.learningRate / batchSizeActual;
        const updateMatrix = (weights, grads) => {
          for (let i = 0; i < weights.length; i++) {
            for (let j = 0; j < weights[i].length; j++) {
              weights[i][j] -= scale * grads[i][j];
            }
          }
        };
        const updateVector = (biases, grads) => {
          for (let i = 0; i < biases.length; i++) biases[i] -= scale * grads[i];
        };

        updateMatrix(this.W4, gradW4);
        updateVector(this.b4, gradB4);
        updateMatrix(this.W3, gradW3);
        updateVector(this.b3, gradB3);
        updateMatrix(this.W2, gradW2);
        updateVector(this.b2, gradB2);
        updateMatrix(this.W1, gradW1);
        updateVector(this.b1, gradB1);
      }

      const avgLoss = epochLoss / total;
      runningLoss = runningLoss * 0.9 + avgLoss * 0.1;
      if ((epoch + 1) % 20 === 0 || epoch === epochs - 1) {
        console.log(`[train-autoencoder] epoch ${epoch + 1}/${epochs} loss=${avgLoss.toFixed(5)} ema=${runningLoss.toFixed(5)}`);
      }
    }
  }

  toJSON({ columns, featureMax } = {}) {
    return {
      version: 1,
      inputSize: this.inputSize,
      latentSize: this.latentSize,
      hiddenSize: this.hiddenSize,
      columns: Array.isArray(columns) ? columns.slice() : null,
      featureStats: {
        max: Array.isArray(featureMax) ? featureMax.slice() : null,
      },
      encoder: [
        { weights: this.W1.map((row) => row.slice()), biases: this.b1.slice(), activation: 'relu' },
        { weights: this.W2.map((row) => row.slice()), biases: this.b2.slice(), activation: 'sigmoid' },
      ],
      decoder: [
        { weights: this.W3.map((row) => row.slice()), biases: this.b3.slice(), activation: 'relu' },
        { weights: this.W4.map((row) => row.slice()), biases: this.b4.slice(), activation: 'linear' },
      ],
      sparsity: {
        rho: this.rho,
        beta: this.beta,
      }
    };
  }
}

function clamp01(x) {
  if (Number.isNaN(x)) return 0;
  if (x < 0) return 0;
  if (x > 1) return 1;
  return x;
}

function normalizeDataset(samples, featureMax) {
  return samples.map((sample) => sample.map((value, idx) => {
    const max = featureMax[idx] || 1;
    return clamp01(value / max);
  }));
}

async function loadDataset(filePath = DATASET_PATH) {
  const txt = await fs.readFile(filePath, 'utf8');
  const parsed = JSON.parse(txt);
  const samples = Array.isArray(parsed.samples) ? parsed.samples : [];
  const columns = Array.isArray(parsed.metadata?.columns) ? parsed.metadata.columns : null;
  const vectors = samples
    .map((entry) => Array.isArray(entry?.vector) ? entry.vector : null)
    .filter((vec) => Array.isArray(vec) && vec.length > 0);
  if (!vectors.length) throw new Error('[train-autoencoder] Dataset contains no valid vectors.');

  const featureMax = vectors[0].map(() => 0);
  for (const vec of vectors) {
    for (let i = 0; i < vec.length; i++) {
      const val = Math.abs(vec[i] || 0);
      if (val > featureMax[i]) featureMax[i] = val;
    }
  }
  for (let i = 0; i < featureMax.length; i++) {
    if (!(featureMax[i] > 0)) featureMax[i] = 1;
  }

  return { columns, vectors, featureMax };
}

async function main() {
  try {
    await fs.access(DATASET_PATH);
  } catch {
    throw new Error(`[train-autoencoder] Dataset not found at ${DATASET_PATH}. Run tools/encode-minions.mjs first.`);
  }

  const { columns, vectors, featureMax } = await loadDataset();
  const normalized = normalizeDataset(vectors, featureMax);
  const inputSize = normalized[0].length;

  console.log(`[train-autoencoder] Loaded ${normalized.length} samples with input size ${inputSize}.`);
  const autoencoder = new SparseAutoencoder(inputSize);
  autoencoder.train(normalized);

  await fs.mkdir(path.dirname(MODEL_PATH), { recursive: true });
  const modelJSON = JSON.stringify(autoencoder.toJSON({ columns, featureMax }), null, 2);
  await fs.writeFile(MODEL_PATH, modelJSON, 'utf8');
  console.log(`[train-autoencoder] Saved model to ${path.relative(process.cwd(), MODEL_PATH)}`);
}

main().catch((err) => {
  console.error('[train-autoencoder] Failed:', err?.stack || err);
  process.exitCode = 1;
});
